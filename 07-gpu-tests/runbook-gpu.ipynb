{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i86 - with GPU Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hostname</th>\n",
       "      <th>arch</th>\n",
       "      <th>gpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kx-Lenovo-H520g</td>\n",
       "      <td>x86_64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hostname    arch  gpu\n",
       "3  kx-Lenovo-H520g  x86_64    1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hosts = pd.read_csv(\"../common/hosts.csv\")\n",
    "supressed_columns = ['ip','user']\n",
    "gpu_hosts = hosts[(hosts.gpu > 0 ) & (hosts.arch == \"x86_64\")]\n",
    "gpu_hosts['ip'].to_csv(r'gpu-ip.txt', header=False, index=None, sep=' ')\n",
    "gpu_hosts.drop(columns=supressed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 14 02:29:25 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.57                 Driver Version: 410.57                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 105...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 25%   31C    P8    N/A /  75W |   3775MiB /  4038MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source ../common/env.sh \n",
    "echo \"ip|name|id|image|ports|runnning\" > containers.csv\n",
    "while read ip; do\n",
    "    export DOCKER_HOST=\"tcp://$ip:2376\"\n",
    "    docker run --runtime=nvidia --rm nvidia/cuda:10.0-base nvidia-smi\n",
    "done <gpu-ip.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n",
      "tensorflow\n",
      "8a198b98fac2639396044db9ae86d3a263113627abf93827b8851bd3d4b570e0\n",
      "[I 02:36:47.287 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\n",
      "[I 02:36:47.304 NotebookApp] Serving notebooks from local directory: /notebooks\n",
      "[I 02:36:47.304 NotebookApp] The Jupyter Notebook is running at:\n",
      "[I 02:36:47.304 NotebookApp] http://(8a198b98fac2 or 127.0.0.1):8888/?token=be7fbe6620713c6da4d129affc3d3c35f0b8ad8866682afe\n",
      "[I 02:36:47.304 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "[C 02:36:47.305 NotebookApp] \n",
      "    \n",
      "    Copy/paste this URL into your browser when you connect for the first time,\n",
      "    to login with a token:\n",
      "        http://(8a198b98fac2 or 127.0.0.1):8888/?token=be7fbe6620713c6da4d129affc3d3c35f0b8ad8866682afe\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source ../common/env.sh \n",
    "echo \"ip|name|id|image|ports|runnning\" > containers.csv\n",
    "while read ip; do\n",
    "    export DOCKER_HOST=\"tcp://$ip:2376\"\n",
    "    docker stop tensorflow\n",
    "    docker rm tensorflow\n",
    "    docker run --name tensorflow -d -p 8888:8888 tensorflow/tensorflow:1.12.0-gpu \n",
    "    sleep 10\n",
    "    docker logs tensorflow 2>&1\n",
    "done <gpu-ip.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU on Jetson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hostname</th>\n",
       "      <th>arch</th>\n",
       "      <th>gpu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tegra-ubuntu</td>\n",
       "      <td>aarch64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hostname     arch  gpu\n",
       "12  tegra-ubuntu  aarch64    1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jetson_hosts = hosts[(hosts.gpu > 0 ) & (hosts.arch == \"aarch64\")]\n",
    "jetson_hosts['ip'].to_csv(r'jetson-ip.txt', header=False, index=None, sep=' ')\n",
    "jetson_hosts.drop(columns=supressed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cudaSamples/deviceQuery Starting...\n",
      "\n",
      " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
      "\n",
      "Detected 1 CUDA Capable device(s)\n",
      "\n",
      "Device 0: \"NVIDIA Tegra X2\"\n",
      "  CUDA Driver Version / Runtime Version          9.0 / 9.0\n",
      "  CUDA Capability Major/Minor version number:    6.2\n",
      "  Total amount of global memory:                 7854 MBytes (8235802624 bytes)\n",
      "  ( 2) Multiprocessors, (128) CUDA Cores/MP:     256 CUDA Cores\n",
      "  GPU Max Clock rate:                            1301 MHz (1.30 GHz)\n",
      "  Memory Clock rate:                             1600 Mhz\n",
      "  Memory Bus Width:                              128-bit\n",
      "  L2 Cache Size:                                 524288 bytes\n",
      "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
      "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
      "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
      "  Total amount of constant memory:               65536 bytes\n",
      "  Total amount of shared memory per block:       49152 bytes\n",
      "  Total number of registers available per block: 32768\n",
      "  Warp size:                                     32\n",
      "  Maximum number of threads per multiprocessor:  2048\n",
      "  Maximum number of threads per block:           1024\n",
      "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
      "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
      "  Maximum memory pitch:                          2147483647 bytes\n",
      "  Texture alignment:                             512 bytes\n",
      "  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n",
      "  Run time limit on kernels:                     No\n",
      "  Integrated GPU sharing Host Memory:            Yes\n",
      "  Support host page-locked memory mapping:       Yes\n",
      "  Alignment requirement for Surfaces:            Yes\n",
      "  Device has ECC support:                        Disabled\n",
      "  Device supports Unified Addressing (UVA):      Yes\n",
      "  Supports Cooperative Kernel Launch:            Yes\n",
      "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
      "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n",
      "  Compute Mode:\n",
      "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
      "\n",
      "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 9.0, NumDevs = 1\n",
      "Result = PASS\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source ../common/env.sh \n",
    "echo \"ip|name|id|image|ports|runnning\" > containers.csv\n",
    "while read ip; do\n",
    "    export DOCKER_HOST=\"tcp://$ip:2376\"\n",
    "    docker run --device=/dev/nvhost-ctrl --device=/dev/nvhost-ctrl-gpu \\\n",
    "    --device=/dev/nvhost-prof-gpu --device=/dev/nvmap --device=/dev/nvhost-gpu \\\n",
    "    --device=/dev/nvhost-as-gpu \\\n",
    "    -v /usr/lib/aarch64-linux-gnu/tegra:/usr/lib/aarch64-linux-gnu/tegra device_query\n",
    "done <jetson-ip.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n",
      "tensorflow\n",
      "a3a5f04656421b1da26e12630282429970b81aabb7915eb7a8c59a02cefc1977\n",
      "standard_init_linux.go:211: exec user process caused \"exec format error\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source ../common/env.sh \n",
    "echo \"ip|name|id|image|ports|runnning\" > containers.csv\n",
    "while read ip; do\n",
    "    export DOCKER_HOST=\"tcp://$ip:2376\"\n",
    "    docker stop tensorflow\n",
    "    docker rm tensorflow\n",
    "    docker run --name tensorflow -d -p 8888:8888 tensorflow/tensorflow:1.12.0-gpu \n",
    "    sleep 10\n",
    "    docker logs tensorflow 2>&1\n",
    "done <jetson-ip.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow seems to not work on arm cpu, I need to cook a image for it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
